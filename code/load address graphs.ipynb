{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"load address graphs.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1896IOAKaQAvDATepKMwHlU_UMJTl_ihH","authorship_tag":"ABX9TyOgdnbjmVLXMRpConmMwLQ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install -q dgl"],"metadata":{"id":"yEiMyM0Lzosi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ae6db3e-6f9c-4c45-e628-ee63f54640fc","executionInfo":{"status":"ok","timestamp":1653644374560,"user_tz":-120,"elapsed":16731,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VurcPGhhzfMF","executionInfo":{"status":"ok","timestamp":1653644374561,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import networkx as nx\n","import torch\n","import torch_geometric\n","from torch_geometric.data import Data\n","import pickle\n","from sklearn import preprocessing\n","import random"]},{"cell_type":"markdown","source":["### Load data\n","\n","Load in edge list (with edge features) and node features."],"metadata":{"id":"1J2mDWzw44KF"}},{"cell_type":"code","source":["edges = pd.read_csv('/content/drive/MyDrive/Augmented_Elliptic/address_level/edgelist_hop3_input.csv')\n","node_features = pd.read_csv('/content/drive/MyDrive/Augmented_Elliptic/address_level/node_address_features.csv').fillna(0).set_index('address')"],"metadata":{"id":"Rph0rPa4Nv1J","executionInfo":{"status":"ok","timestamp":1653644402497,"user_tz":-120,"elapsed":27947,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Data pre-processing\n","\n","First, scale the edge and node features using the `StandardScaler()` from the `sklearn` package. Because we don't use cross-validation to choose the hyperparameters for our models, there is no data leakage associated with scaling based on the whole data set (as opposed to just the training set). "],"metadata":{"id":"xvKBjj-05PQ0"}},{"cell_type":"code","source":["# Store names for future use\n","names = node_features.columns"],"metadata":{"id":"9dc7QtkZ1Vju","executionInfo":{"status":"ok","timestamp":1653644402498,"user_tz":-120,"elapsed":57,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["scaler1 = preprocessing.StandardScaler()\n","scaler2 = preprocessing.StandardScaler()\n","\n","# Scale edge features\n","edges = pd.concat([edges[['node', 'class', 'entity', 'category', 'node_source', 'node_sink']], pd.DataFrame(scaler1.fit_transform(edges[['txn_amount', 'fee', 'interactions', 'two_way']]))], axis = 1)\n","edges.columns = ['node', 'class', 'entity', 'category', 'node_source', 'node_sink', 'txn_amount', 'fee', 'interactions', 'two_way']\n","# Scale node features\n","node_features = pd.DataFrame(scaler2.fit_transform(node_features), index = node_features.index, columns=names)\n"],"metadata":{"id":"SVcqVVHgOMIp","executionInfo":{"status":"ok","timestamp":1653644404911,"user_tz":-120,"elapsed":2465,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Labels object - one label for each address\n","labels = edges[['node', 'class']].groupby(['node']).agg({'class': 'max'})\n","labels = labels.replace(to_replace = 2, value = 1)"],"metadata":{"id":"Xx6sERFMR0Gu","executionInfo":{"status":"ok","timestamp":1653644407444,"user_tz":-120,"elapsed":2557,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Next, we need to extract and store the data to build each of the address-level sub-graphs. The code below extracts the label, edges (and edge features) and node features associated with each input address.  "],"metadata":{"id":"49FlGmEMADRl"}},{"cell_type":"code","source":["graphs = dict()\n","\n","# Assign class\n","lab = labels.groupby('node')    \n","graphs['label'] = [lab.get_group(x) for x in lab.groups]\n","\n","# Assign edge features\n","ef = edges.groupby('node')\n","graphs['edge_features'] = [ef.get_group(x) for x in ef.groups]\n","\n","# Assign node features\n","#Filter nf df for all nodes in that graph - list of df with node features for each graph\n","node_list = [ef.get_group(x)['node_source'].append(ef.get_group(x)['node_sink']).unique() for x in ef.groups]\n","graphs['node_features'] = [node_features.filter(items = x, axis = 0) for x in node_list]\n"],"metadata":{"id":"4oiNNaxdV0vm","executionInfo":{"status":"ok","timestamp":1653644557346,"user_tz":-120,"elapsed":149927,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Finally, we use the `networkx` and `torch_geometric` packages t construct the graphs with the data listed above. This list of graphs will be used to train our graph-level classification algorithm. "],"metadata":{"id":"XFDnjwWzAwEs"}},{"cell_type":"code","source":["graphs_transf = list(range(len(graphs['label'])))\n","\n","for g in range(len(graphs['label'])):\n","    # Create graph from edge list and attach edge features\n","    edge_index = nx.from_pandas_edgelist(graphs['edge_features'][g], 'node_source', 'node_sink', edge_attr = ['node', 'entity', 'category', 'txn_amount', 'fee', 'interactions', 'two_way'], create_using = nx.DiGraph)\n","    # Convert to torch_geometric data object\n","    data = torch_geometric.utils.from_networkx(edge_index)\n","    # Add node features   \n","    data.x = torch.tensor(np.array(graphs['node_features'][g]), dtype = torch.long)\n","    # Add class\n","    data.y = graphs['label'][g]['class'] #label of the graph\n","    # Add edge features as tensor\n","    data.edge_attr = torch.stack((data.txn_amount, data.fee, data.interactions, data.two_way), dim = 1)\n","    #Add data for node id, category and entity\n","    data.node = str(data.node[0])\n","    if type(data.category[0]) == torch.Tensor:\n","      data.category = str(data.category[0].numpy())\n","      data.entity = str(data.entity[0].numpy())\n","    else:\n","      data.category = data.category[0]\n","      data.entity = data.entity[0]\n","    # Drop individual edge features as passed to networkx graph\n","    data.txn_amount = None\n","    data.fee = None\n","    data.interactions = None\n","    data.two_way = None\n","    #Assign to list\n","    graphs_transf[g] = data\n"],"metadata":{"id":"siS53d40d13y","executionInfo":{"status":"ok","timestamp":1653644856660,"user_tz":-120,"elapsed":299332,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["len(graphs_transf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tv1KVxtHryTO","executionInfo":{"status":"ok","timestamp":1653644856661,"user_tz":-120,"elapsed":15,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"ead3da56-1648-43c9-8460-ad1dd438dc55"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["102075"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["classes = {graphs_transf[i].y.index.map(str)[0]: graphs_transf[i].y.item() for i in range(len(graphs_transf))}\n","classes_1 = dict(filter(lambda i: i[1] == 1, classes.items()))\n","classes_0 = dict(filter(lambda i: i[1] == 0, classes.items()))\n","\n","print(f'Number of high risk addresses: {len(classes_1.keys())}')\n","print(f'Number of safe addresses: {len(classes_0.keys())}')\n","\n","random.seed(1993)\n","classes_all_keys = list(classes.keys()) \n","\n","train_share = 0.9\n","# Sample training and test sets\n","train_keys = random.sample(classes_all_keys, k = round(train_share*len(classes_all_keys)))\n","test_keys = [*filter(lambda i: i not in train_keys, classes_all_keys)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3qAyAIG3Oi0","executionInfo":{"status":"ok","timestamp":1653645116246,"user_tz":-120,"elapsed":259593,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"8a6a3919-6790-4919-af5d-08ec2b81ed18"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of high risk addresses: 10496\n","Number of safe addresses: 91579\n"]}]},{"cell_type":"code","source":["# Separate training set into 0 and 1s\n","classes_train = {i: classes[i] for i in train_keys}\n","classes_train_0 = {key:value for (key, value) in classes_train.items() if value == 0}\n","classes_train_1 = {key:value for (key, value) in classes_train.items() if value == 1}\n"],"metadata":{"id":"q5a4US2Y3a5Q","executionInfo":{"status":"ok","timestamp":1653645116250,"user_tz":-120,"elapsed":97,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Undersample safe class to match high risk class\n","sample_safe = random.sample(list(classes_train_0.keys()), k = len(classes_train_1.keys()))\n","\n","# Combine training classes\n","classes_train_trim_0 = dict(filter(lambda i: i[0] in sample_safe, classes_train_0.items()))\n","classes_train_balanced = {**classes_train_1, **classes_train_trim_0}\n","\n","# Print test shares\n","classes_test = {i: classes[i] for i in test_keys}\n","classes_test_0 = dict(filter(lambda i: i[1] == 0, classes_test.items()))\n","classes_test_1 = dict(filter(lambda i: i[1] == 1, classes_test.items()))\n","\n","print(f'Number of high risk test addresses: {len(classes_test_1.keys())}')\n","print(f'Number of safe test addresses: {len(classes_test_0.keys())}')\n","\n","print(f'Number of high risk train addresses: {len(classes_train_1.keys())}')\n","print(f'Number of safe train addresses: {len(classes_train_trim_0.keys())}')\n","\n","# Construct train and test subsets\n","train_dataset = [graph for graph in graphs_transf if graph.node in list(classes_train_balanced.keys())] \n","test_dataset = [graph for graph in graphs_transf if graph.node in test_keys]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnnP5Pnc3dyO","executionInfo":{"status":"ok","timestamp":1653645250877,"user_tz":-120,"elapsed":134718,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"828aa5aa-c1ae-4e26-fe7d-36255a841d6a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of high risk test addresses: 1058\n","Number of safe test addresses: 9149\n","Number of high risk train addresses: 9438\n","Number of safe train addresses: 9438\n"]}]},{"cell_type":"code","source":["dataset = [train_dataset, test_dataset]"],"metadata":{"id":"0ih1nRAsTbgf","executionInfo":{"status":"ok","timestamp":1653645250881,"user_tz":-120,"elapsed":90,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Augmented_Elliptic/address_level/address_subgraphs.pkl', 'wb') as File:\n","  pickle.dump(dataset, File)\n","  "],"metadata":{"id":"dnfiYQxP8Hdw","executionInfo":{"status":"ok","timestamp":1653645272669,"user_tz":-120,"elapsed":21875,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"25iXLy_NZBrv","executionInfo":{"status":"ok","timestamp":1653645272670,"user_tz":-120,"elapsed":52,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"execution_count":16,"outputs":[]}]}